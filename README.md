# ðŸ•µï¸â€â™‚ï¸ Online Fake Review Detection System

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-Deep%20Learning-red)
![Transformers](https://img.shields.io/badge/Hugging%20Face-BERT-yellow)
![Scikit-Learn](https://img.shields.io/badge/Library-Scikit--Learn-orange)
![Google Colab](https://img.shields.io/badge/Environment-Google%20Colab-f9ab00)

> A comprehensive system to detect deceptive online reviews using a hybrid approach of Classic Machine Learning and State-of-the-Art Deep Learning (BERT).

---

## ðŸ“‘ Table of Contents
- [Abstract](#-abstract)
- [Key Features](#-key-features)
- [System Architecture](#-system-architecture)
- [Dataset](#-dataset)
- [Tech Stack](#-tech-stack)
- [Installation & Setup](#-installation--setup)
- [How to Run (Step-by-Step)](#-how-to-run-step-by-step)
- [Performance Results](#-performance-results)
- [Project Team](#-project-team)

---

## ðŸ“ Abstract
Online reviews are critical for consumer decision-making, but the rise of fake reviews threatens trust in e-commerce. This project develops an automated detection system that distinguishes between **Original Reviews (OR)** and **Computer Generated (CG)** fake reviews.

We implement and compare two methodologies:
1.  **Classic Machine Learning:** Using TF-IDF vectorization with algorithms like Random Forest and Logistic Regression.
2.  **Deep Learning:** Fine-tuning a pre-trained **BERT (Bidirectional Encoder Representations from Transformers)** model for context-aware classification.

**Outcome:** The fine-tuned BERT model achieved a state-of-the-art accuracy of **98%**, significantly outperforming traditional methods.

---

## ðŸš€ Key Features
*   **Dual-Approach Pipeline:** Seamless comparison between statistical ML and Deep Learning.
*   **Data Preprocessing:** Automated cleaning, stop-word removal, and label encoding.
*   **State-of-the-Art Model:** Utilizes `bert-base-uncased` for deep contextual understanding.
*   **Model Persistence:** Saves trained models (`.pkl` and `.pth`) for reuse without retraining.
*   **Inference Engine:** A dedicated function to classify new, unseen user reviews in real-time.

---

## ðŸ— System Architecture
*(You can insert your diagram image here)*

1.  **Input:** Raw User Review.
2.  **Preprocessing:** Tokenization (BERT) or Vectorization (TF-IDF).
3.  **Model Inference:** Loaded trained model predicts probability.
4.  **Output:** Classification Label (Fake/Real) + Confidence Score.

---

## ðŸ“Š Dataset
The project uses the **Fake Reviews Dataset** containing labeled reviews:
*   **OR (Original Reviews):** Genuine user feedback.
*   **CG (Computer Generated):** Fake reviews generated by AI.

**Structure:**
*   `text_`: The review content.
*   `label`: The classification target ('OR' or 'CG').

---

## ðŸ’» Tech Stack
*   **Language:** Python 3.x
*   **Environment:** Google Colab (Recommended for GPU)
*   **Deep Learning:** PyTorch, Transformers (Hugging Face)
*   **Machine Learning:** Scikit-learn, Pandas, NumPy
*   **Utilities:** Joblib (Model Saving), Matplotlib/Seaborn (Visualization)

---

## âš™ï¸ Installation & Setup

### Prerequisites
*   A Google Account (to use Google Colab).
*   *Or* a local Python environment with GPU support (CUDA).

### Required Libraries
If running locally, install dependencies using:
```bash
pip install torch transformers scikit-learn pandas numpy matplotlib seaborn
â–¶ï¸ How to Run (Step-by-Step)

The easiest way to run this project is using Google Colab.
Step 1: Prepare the Environment

    Open the project notebook (Fake_Review_Detection.ipynb) in Google Colab.

    Go to Runtime > Change runtime type > Select T4 GPU (Crucial for BERT training).

Step 2: Upload Data

    Click the folder icon on the left sidebar in Colab.

    Upload the fake reviews dataset.csv file.

Step 3: Execute the Pipeline

Run the notebook cells in order:

    Imports: Loads necessary libraries.

    Data Loading: Reads the CSV and cleans the text.

    Classic ML Training: Runs TF-IDF, trains RF/LR/NB models, and displays results.

    BERT Training:

        Tokenizes the data.

        Fine-tunes the BERT model for 4 epochs (takes approx. 20-30 mins).

        Evaluates on the test set.

Step 4: Run Inference (Test Custom Reviews)

Go to the final section of the notebook ("Prediction System") and run the cell. You can input your own text:
code Python

    
review_text = "This product is amazing! I bought it yesterday."
result = predict_sentiment(review_text)
print(result) 
# Output: "Real Review"

  

ðŸ“ˆ Performance Results

We evaluated models on a held-out test set. Here is the summary:
Model	Accuracy	F1-Score
BERT (Deep Learning)	98%	0.98
Random Forest	85%	0.85
Logistic Regression	86%	0.86
Naive Bayes	84%	0.84

    Conclusion: BERT significantly outperforms classic models due to its ability to understand the semantic context and subtle nuances of deceptive language.
